# Big Data Computing Projects
This repository contains the solutions to three homework assignments developed for the **Big Data Computing** course. The implementations make use of **Apache Spark** for distributed data processing and are written in **Python** using the PySpark API.

## Authors

* [@umberto-bianchin](https://www.github.com/umberto-bianchin)
* [@Massimo-Vettorello](https://github.com/Massimo-Vettorello)

## ðŸ§  Overview

### ðŸ”¹ HW1 â€“ Fair Assignment and Statistics with MapReduce
Implements a two-phase MapReduce pipeline in Spark to:
- Assign data points to the closest centroid using Lloyd's algorithm.
- Compute group-based statistics (counts per group per centroid) to evaluate fairness.
- Analyze memory usage and communication overhead in the distributed setting.

Relevant files:
- `G97HW1.py` â€“ main logic
- `G97HW1analysis.docx` â€“ theoretical memory cost analysis

---

### ðŸ”¹ HW2 â€“ Fair K-Means with Synthetic Data
Implements and compares the **standard Lloydâ€™s algorithm** and its **fair variant**, using Spark's parallelism. The fair variant ensures demographic balance between groups A and B within each cluster.

Additional features:
- Scalability testing with different numbers of executors
- Timing of different pipeline stages
- Support for synthetic datasets with controlled group imbalance

Relevant files:
- `G97HW2.py` â€“ clustering logic
- `G97GEN.py` â€“ synthetic dataset generator
- `G97HW2form.docx` â€“ scalability test results and explanations

---

### ðŸ”¹ HW3 â€“ Heavy Hitters with Count-Min and Count Sketch
Processes a data stream using Spark Streaming to:
- Track item frequencies using **Count-Min Sketch** and **Count Sketch**.
- Identify the **Top-K heavy hitters** in the stream.
- Evaluate estimation accuracy for both sketches based on average relative error.

Features:
- Real-time processing with custom stopping criteria
- Accuracy experiments for different values of K and sketch width W

Relevant files:
- `G97HW3.py` â€“ streaming logic
- `G97HW3Form.docx` â€“ experiment results and analysis

---

## ðŸ”§ Technologies Used
- Python 3
- Apache Spark (PySpark)
- Spark Streaming
- HDFS (for input data)
- NumPy, statistics, collections